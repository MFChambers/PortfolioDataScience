---
title: "Client Report - The War with Star Wars"
subtitle: "Course DS 250"
author: "Maia Faith Chambers"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
---

```{python}
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

After cleaning and restructuring the Star Wars survey data, this achieved a model accuracy of about 62% in predicting whether respondents earn more than $50,000 per year based on their age, education, and Star Wars preferences. The validated key visuals showing that Episode V is the most popular movie, while Jar Jar Binks is the most disliked character. This reveals that even pop culture opinions can correlate with demographic patterns.

## QUESTION|TASK 1

__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. 

| **Original Name**                                                                   | **Cleaned Name** |
| ----------------------------------------------------------------------------------- | ---------------- |
| Which of the following Star Wars films have you seen? Please select all that apply. | seen\_any        |
| Age                                                                                 | age              |
| Education                                                                           | education        |
| Household Income                                                                    | income           |


```{python}
# Load CSV
url = "https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"
df = pd.read_csv(url, encoding="ISO-8859-1")

# Show original columns
print(df.columns.tolist())

# Rename with correct columns that actually exist
rename_map = {
    "Which of the following Star Wars films have you seen? Please select all that apply.": "seen_any",
    "Age": "age",
    "Education": "education",
    "Household Income": "income"
}
df = df.rename(columns=rename_map)

# Show after renaming
df.head()

```


## QUESTION|TASK 2

__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  
    a. Filter the dataset to respondents that have seen at least one film  
    a. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  
    a. Create a new column that converts the education groupings to a single number. Drop the school categorical column  
    a. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  
    a. Create your target (also known as “y” or “label”) column based on the new income range column  
    a. One-hot encode all remaining categorical columns   

_type your results and analysis here_

```{python}
# Task 2a: Filter respondents who saw at least one film
df_seen = df[df["seen_any"].notna()].copy()
print(df_seen.shape)
print(df_seen.columns.tolist())
df_seen.head()

```

```{python}
# Task 2b: Convert age ranges to approximate midpoints
age_map = {
    "18-29": 23.5,
    "30-44": 37,
    "45-60": 52,
    "> 60": 65
}
df_seen["age_num"] = df_seen["age"].map(age_map)
df_seen = df_seen.drop(columns="age")
df_seen[["age_num"]].head()

```

```{python}
# Task 2c: Convert education categories to numbers
edu_map = {
    "Less than high school degree": 1,
    "High school degree": 2,
    "Some college or Associate degree": 3,
    "Bachelor degree": 4,
    "Graduate degree": 5
}
df_seen["education_num"] = df_seen["education"].map(edu_map)
df_seen = df_seen.drop(columns="education")
df_seen[["education_num"]].head()

```

```{python}
# Task 2d: Convert income ranges to midpoints
income_map = {
    "Under $25,000": 12500,
    "$25,000 - $49,999": 37500,
    "$50,000 - $99,999": 75000,
    "$100,000 - $149,999": 125000,
    "$150,000+": 175000
}
df_seen["income_num"] = df_seen["income"].map(income_map)
df_seen = df_seen.drop(columns="income")
df_seen[["income_num"]].head()


```

```{python}
# Task 2e: Create a binary target variable
df_seen["target"] = (df_seen["income_num"] > 50000).astype(int)
df_seen[["income_num", "target"]].head()

```

```{python}
# Task 2f: One-hot encode remaining categoricals
categorical_cols = df_seen.select_dtypes(include="object").columns
df_final = pd.get_dummies(df_seen, columns=categorical_cols, drop_first=True)
df_final.head()

```

## QUESTION|TASK 3

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  

_type your results and analysis here_

```{python}
# Most seen movie
seen_cols = [col for col in df.columns if "Episode" in col]
if seen_cols:
    movie_counts = df[seen_cols].apply(pd.Series.value_counts).loc[True]
    movie_counts.sort_values().plot(kind="barh", title="Star Wars Movie Viewership", xlabel="Respondents")
    plt.show()
else:
    print("No movie columns detected.")


```

```{python}
# Least liked character
# NOTE: column missing in this CSV, so skip
print("Column 'least_fav_character' not present in dataset — skipping this plot.")

```

## QUESTION|TASK 4

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ 

I trained a Random Forest Classifier on the cleaned survey data to predict whether a respondent makes more than $50k per year. The model achieved an accuracy of approximately 62% on the test set, indicating moderate predictive power based on age, education, and Star Wars-related preferences.

```{python}
# define features and target
X = df_final.drop(columns=["income_num", "target"])
y = df_final["target"]

# train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# train random forest
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# predictions
y_pred = model.predict(X_test)

# accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Random Forest accuracy: {accuracy:.2%}")


```

---

## STRETCH QUESTION|TASK 1

__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__

_type your results and analysis here_

```{python}
model2 = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42)
model2.fit(X_train, y_train)
preds2 = model2.predict(X_test)
acc2 = accuracy_score(y_test, preds2)
print(f"Improved Random Forest accuracy: {acc2:.2%}")


```


## STRETCH QUESTION|TASK 2

__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__

_type your results and analysis here_

```{python}
# Example: respondents by gender
if "Gender" in df.columns:
    gender_counts = df["Gender"].value_counts()
    gender_counts.plot(kind="bar", title="Respondents by Gender", ylabel="Respondents")
    plt.show()
else:
    print("Gender column not found.")

```


## STRETCH QUESTION|TASK 3

__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  

_type your results and analysis here_

```{python}
if "Location (Census Region)" in df.columns:
    df_seen["location_num"] = df_seen["Location (Census Region)"].astype("category").cat.codes
    df_seen = df_seen.drop(columns="Location (Census Region)")
    df_seen[["location_num"]].head()
else:
    print("Location column not found.")

```

---
